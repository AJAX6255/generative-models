{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" (FisherGAN)\n",
    "\n",
    "From the abstract:\n",
    "\"In this paper we introduce Fisher GAN which fits within the \n",
    "Integral Probability Metrics (IPM) framework for training GANs. \n",
    "Fisher GAN defines a critic with a data dependent constraint on \n",
    "its second order moments. We show in this paper that Fisher GAN \n",
    "allows for stable and time efficient training that does not \n",
    "compromise the capacity of the critic, and does not need data \n",
    "independent constraints such as weight clipping.\"\n",
    "\n",
    "Integral Probability Metrics (IPM) framework simply means that\n",
    "the outputs of the discriminator can be interpretted \n",
    "probabilistically. This is similar to WGAN/WGAN-GP. Whereas\n",
    "WGAN-GP uses a penalty on the gradients of the critic, FisherGAN\n",
    "imposes a constraint on the second order moments of the critic.\n",
    "Also, the Fisher IPM corresponds to the Chi-squared distance\n",
    "between distributions.\n",
    "\n",
    "The main empirical claims are that FisherGAN yields better\n",
    "inception scores and has less computational overhead than WGAN.\n",
    "\n",
    "https://arxiv.org/pdf/1606.07536.pdf\n",
    "\"\"\"\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "from load_data import get_data\n",
    "\n",
    "def to_var(x):\n",
    "    \"\"\" Make a tensor cuda-erized and requires gradient \"\"\"\n",
    "    return to_cuda(x).requires_grad_()\n",
    "\n",
    "def to_cuda(x):\n",
    "    \"\"\" Cuda-erize a tensor \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "\n",
    "# Enable Jupyter notebook plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in binarized MNIST data, separate into data loaders\n",
    "train_iter, val_iter, test_iter = get_data()\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator. Input is noise, output is a generated image. \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.generate = nn.Linear(hidden_dim, image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        generation = torch.sigmoid(self.generate(activated))\n",
    "        return generation\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Discriminator. Input is an image (real or generated), output is P(generated).\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        self.discriminate = nn.Linear(hidden_dim, output_dim)     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        discrimination = torch.sigmoid(self.discriminate(activated))\n",
    "        return discrimination\n",
    "\n",
    "\n",
    "class FisherGAN(nn.Module):\n",
    "    \"\"\" Super class to contain both Discriminator (D) and Generator (G) \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.G = Generator(image_size, hidden_dim, z_dim)\n",
    "        self.D = Discriminator(image_size, hidden_dim, output_dim)\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    \n",
    "class FisherGANTrainer:\n",
    "    \"\"\" Object to hold data iterators, train a GAN variant \n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_iter, val_iter, test_iter, viz=False):\n",
    "        self.model = to_cuda(model)\n",
    "        self.name = model.__class__.__name__\n",
    "        \n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "        \n",
    "        self.Glosses = []\n",
    "        self.Dlosses = []\n",
    "        \n",
    "        self.viz = viz\n",
    "            \n",
    "    def train(self, num_epochs, G_lr=1e-4, D_lr=1e-4, D_steps=1, LAMBDA=0., RHO=1e-6):\n",
    "        \"\"\" Train FisherGAN using IPM framework\n",
    "            Logs progress using G loss, D loss, G(x), D(G(x)), visualizations of Generator output.\n",
    "\n",
    "        Inputs:\n",
    "            num_epochs: int, number of epochs to train for\n",
    "            G_lr: float, learning rate for generator's Adam optimizer (default 1e-4)\n",
    "            D_lr: float, learning rate for discriminator's Adam optimizer (default 1e-4)\n",
    "            D_steps: int, training step ratio for how often to train D compared to G (default 1)\n",
    "            LAMBDA: float, initial weight on constraint term (default 0.)\n",
    "            RHO: float, quadratic penalty weight (default 1e-6)\n",
    "        \"\"\"\n",
    "        # Initialize alpha\n",
    "        self.LAMBDA = to_var(torch.tensor([LAMBDA]))\n",
    "        self.RHO = to_var(torch.tensor(RHO))\n",
    "        \n",
    "        # Initialize optimizers\n",
    "        G_optimizer = torch.optim.Adam(params=[p for p in self.model.G.parameters() if p.requires_grad], lr=G_lr)\n",
    "        D_optimizer = torch.optim.Adam(params=[p for p in self.model.D.parameters() if p.requires_grad], lr=D_lr)\n",
    "    \n",
    "        # Approximate steps/epoch given D_steps per epoch --> roughly train in the same way as if D_step (1) == G_step (1)\n",
    "        epoch_steps = int(np.ceil(len(train_iter) / (D_steps))) \n",
    "        \n",
    "        # Begin training\n",
    "        for epoch in tqdm_notebook(range(1, num_epochs+1)):\n",
    "            self.model.train()\n",
    "            G_losses, D_losses = [], []\n",
    "            \n",
    "            for _ in range(epoch_steps):\n",
    "                \n",
    "                D_step_loss = []\n",
    "                \n",
    "                for _ in range(D_steps): \n",
    "\n",
    "                    # Reshape images\n",
    "                    images = self.process_batch(self.train_iter)\n",
    "\n",
    "                    # TRAINING D: Zero out gradients for D\n",
    "                    D_optimizer.zero_grad()\n",
    "\n",
    "                    # Train the discriminator to learn to discriminate between real and generated images\n",
    "                    D_loss = self.train_D(images)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    D_loss.backward()\n",
    "                    \n",
    "                    # Minimize lambda for 'artisinal SGD'\n",
    "                    print(self.LAMBDA.grad)\n",
    "                    self.LAMBDA += self.RHO*self.LAMBDA.grad\n",
    "                    self.LAMBDA = to_cuda(self.LAMBDA.detach().requires_grad_(True))\n",
    "                    \n",
    "                    # Now step optimizer\n",
    "                    D_optimizer.step()\n",
    "                    \n",
    "                    # Log results, backpropagate the discriminator network\n",
    "                    D_step_loss.append(D_loss.item())\n",
    "                                                        \n",
    "                # So that G_loss and D_loss have the same number of entries.\n",
    "                D_losses.append(np.mean(D_step_loss))\n",
    "                \n",
    "                # TRAINING G: Zero out gradients for G\n",
    "                G_optimizer.zero_grad()\n",
    "\n",
    "                # Train the generator to generate images that fool the discriminator\n",
    "                G_loss = self.train_G(images)\n",
    "                \n",
    "                # Log results, update parameters\n",
    "                G_losses.append(G_loss.item())\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "            \n",
    "            # Save progress\n",
    "            self.Glosses.extend(G_losses)\n",
    "            self.Dlosses.extend(D_losses)\n",
    "                            \n",
    "            # Progress logging\n",
    "            print (\"Epoch[%d/%d], G Loss: %.4f, D Loss: %.4f\"\n",
    "                   %(epoch, num_epochs, np.mean(G_losses), np.mean(D_losses))) \n",
    "            self.num_epochs = epoch\n",
    "            \n",
    "            # Visualize generator progress\n",
    "            self.generate_images(epoch)\n",
    "            \n",
    "            if self.viz:\n",
    "                plt.show()\n",
    "                \n",
    "    def train_D(self, images):\n",
    "        \"\"\" Run 1 step of training for discriminator\n",
    "\n",
    "        Input:\n",
    "            images: batch of images (reshaped to [batch_size, 784])\n",
    "        Output:\n",
    "            D_loss: FisherGAN IPM loss\n",
    "        \"\"\"    \n",
    "        # Generate labels (ones indicate real images, zeros indicate generated)\n",
    "        X_labels = to_cuda(torch.ones(images.shape[0], 1)) \n",
    "        G_labels = to_cuda(torch.zeros(images.shape[0], 1)) \n",
    "        \n",
    "        # Classify the real batch images, get the loss for these \n",
    "        DX_score = self.model.D(images)\n",
    "        \n",
    "        # Sample noise z, generate output G(z), discriminate D(G(z))\n",
    "        noise = self.compute_noise(images.shape[0], model.z_dim)\n",
    "        G_output = self.model.G(noise)\n",
    "        DG_score = self.model.D(G_output)\n",
    "        \n",
    "        # First and second order central moments (Gaussian assumed)\n",
    "        DX_moment_1, DG_moment_1  = DX_score.mean(), DG_score.mean()\n",
    "        DX_moment_2, DG_moment_2 = (DX_score**2).mean(), (DG_score**2).mean()\n",
    "        \n",
    "        # Compute constraint on second order moments\n",
    "        OMEGA = 1 - (0.5*DX_moment_2 + 0.5*DG_moment_2)\n",
    "\n",
    "        # Compute loss (Eqn. 9, but differs slightly since we optimize negative gradients)\n",
    "        D_loss = -((DX_moment_1-DG_moment_1) + self.LAMBDA*OMEGA - (self.RHO/2)*(OMEGA**2))\n",
    "\n",
    "        return D_loss\n",
    "    \n",
    "    def train_G(self, images):\n",
    "        \"\"\" Run 1 step of training for generator\n",
    "        \n",
    "        Input:\n",
    "            images: batch of images reshaped to [batch_size, -1]    \n",
    "        Output:\n",
    "            G_loss: FisherGAN IPM loss\n",
    "        \"\"\" \n",
    "        \n",
    "        # Get noise (denoted z), classify it using G, then classify the output of G using D.\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim) # z\n",
    "        G_output = self.model.G(noise) # G(z)\n",
    "        DG_score = self.model.D(G_output) # D(G(z))\n",
    "        \n",
    "        # Compute loss by minimizing mean difference\n",
    "        G_loss = -DG_score.mean()\n",
    "        \n",
    "        return G_loss\n",
    "    \n",
    "    def compute_noise(self, batch_size, z_dim):\n",
    "        \"\"\" Compute random noise for the generator to learn to make images from \"\"\"\n",
    "        return to_cuda(torch.randn(batch_size, z_dim))\n",
    "    \n",
    "    def process_batch(self, iterator):\n",
    "        \"\"\" Generate a process batch to be input into the discriminator D \"\"\"\n",
    "        images, _ = next(iter(iterator))\n",
    "        images = to_cuda(images.view(images.shape[0], -1))\n",
    "        return images\n",
    "    \n",
    "    def generate_images(self, epoch, num_outputs=36, save=True):\n",
    "        \"\"\" Visualize progress of generator learning \"\"\"\n",
    "        # Turn off any regularization\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Sample noise vector\n",
    "        noise = self.compute_noise(num_outputs, self.model.z_dim)\n",
    "        \n",
    "        # Transform noise to image\n",
    "        images = self.model.G(noise)\n",
    "        \n",
    "        # Reshape to proper image size\n",
    "        images = images.view(images.shape[0], 28, 28)\n",
    "        \n",
    "        # Plot\n",
    "        plt.close()\n",
    "        size_figure_grid = int(num_outputs**0.5)\n",
    "        fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "        for i, j in product(range(size_figure_grid), range(size_figure_grid)):\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)\n",
    "            ax[i,j].cla()\n",
    "            ax[i,j].imshow(images[i+j].data.numpy(), cmap='gray') \n",
    "        \n",
    "        # Save images if desired\n",
    "        if save:\n",
    "            outname = '../viz/' + self.name + '/'\n",
    "            if not os.path.exists(outname):\n",
    "                os.makedirs(outname)\n",
    "            torchvision.utils.save_image(images.unsqueeze(1).data, \n",
    "                                         outname + 'reconst_%d.png'\n",
    "                                         %(epoch), nrow = 5)\n",
    "    \n",
    "    def viz_loss(self):\n",
    "        \"\"\" Visualize loss for the generator, discriminator \"\"\"\n",
    "        # Set style, figure size\n",
    "        plt.style.use('ggplot')\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "\n",
    "        # Plot Discriminator loss in red, Generator loss in green\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Dlosses, 'r')\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Glosses, 'g')\n",
    "        \n",
    "        # Add legend, title\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, savepath):\n",
    "        \"\"\" Save model state dictionary \"\"\"\n",
    "        torch.save(self.model.state_dict(), savepath)\n",
    "    \n",
    "    def load_model(self, loadpath):\n",
    "        \"\"\" Load state dictionary into model \"\"\"\n",
    "        state = torch.load(loadpath)\n",
    "        self.model.load_state_dict(state)\n",
    "\n",
    "\n",
    "model = FisherGAN(image_size=784, \n",
    "                  hidden_dim=256, \n",
    "                  z_dim=128)\n",
    "\n",
    "trainer = FisherGANTrainer(model=model, \n",
    "                           train_iter=train_iter, \n",
    "                           val_iter=val_iter, \n",
    "                           test_iter=test_iter,\n",
    "                           viz=True)\n",
    "\n",
    "trainer.train(num_epochs=1, \n",
    "              G_lr=1e-4, \n",
    "              D_lr=1e-4, \n",
    "              D_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
