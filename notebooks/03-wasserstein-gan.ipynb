{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" (WGAN)\n",
    "Wasserstein GAN as laid out in original paper\n",
    "https://arxiv.org/abs/1701.07875\n",
    "\n",
    "WGAN utilizes the Wasserstein distance to produce a value function which \n",
    "has better theoretical properties than the vanilla GAN. WGAN requires \n",
    "that the discriminator (aka Critic because it is not actually classifying) \n",
    "lies in the space of 1-Lipschitz functions, enforced via weight clipping. \n",
    "The discriminator approximates the Wasserstein distance.\n",
    "\n",
    "\"\"\"\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "from load_data import get_data\n",
    "\n",
    "def to_var(x):\n",
    "    \"\"\" function to automatically cudarize.. \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "# Load in data, separate into data loaders\n",
    "train_iter, val_iter, test_iter = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, image_size, hidden_dim, z_dim):\n",
    "        \"\"\" Generator. Input is noise, output is a generated image. \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.generate = nn.Linear(hidden_dim, image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        generation = F.sigmoid(self.generate(activated))\n",
    "        return generation\n",
    "        \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size, hidden_dim, output_dim):\n",
    "        \"\"\" Discriminator / Critic (as it's not trained to classify). Input is an image (real or generated), output is P(generated). \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        self.discriminate = nn.Linear(hidden_dim, output_dim)     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        discrimination = F.sigmoid(self.discriminate(activated))\n",
    "        return discrimination\n",
    "    \n",
    "class WGAN(nn.Module):\n",
    "    def __init__(self, image_size, hidden_dim, z_dim, output_dim = 1):\n",
    "        \"\"\" Super class to contain both Discriminator (D) and Generator (G) \"\"\"\n",
    "        super(WGAN, self).__init__()\n",
    "        self.G = Generator(image_size, hidden_dim, z_dim)\n",
    "        self.D = Discriminator(image_size, hidden_dim, output_dim)\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "    \n",
    "class Trainer:\n",
    "    def __init__(self, train_iter, val_iter, test_iter):\n",
    "        \"\"\" Object to hold data iterators, train a GAN variant \"\"\"\n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "    \n",
    "    def train(self, model, num_epochs, G_lr = 5e-5, D_lr = 5e-5, D_steps = 5, clip = 0.01):\n",
    "        \"\"\" Train a Wasserstein GAN\n",
    "            Logs progress using G loss, D loss, G(x), D(G(x)), visualizations of Generator output.\n",
    "\n",
    "        Inputs:\n",
    "            model: class, initialized GAN nn.module\n",
    "            num_epochs: int, number of epochs to train for\n",
    "            G_lr: float, learning rate for generator's Adam optimizer (default 5e-5)\n",
    "            D_lr: float, learning rate for discriminator's Adam optimizer (default 5e-5)\n",
    "            D_steps: int, training step ratio for how often to train D compared to G (default 5)\n",
    "            clip: float, bound for parameters [-c, c] to crudely ensure K-Lipschitz (default 0.01, or range [-0.01, 0.01])\n",
    "        Outputs:\n",
    "            model: trained WGAN instance \n",
    "        \"\"\"\n",
    "        G_optimizer = torch.optim.RMSprop(params=[p for p in model.G.parameters() if p.requires_grad], lr=G_lr)\n",
    "        D_optimizer = torch.optim.RMSprop(params=[p for p in model.D.parameters() if p.requires_grad], lr=D_lr)\n",
    "        \n",
    "        # Approximate steps/epoch given D_steps per epoch --> roughly train in the same way as if D_step (1) == G_step (1)\n",
    "        epoch_steps = int(np.ceil(len(train_iter) / (D_steps))) \n",
    "        \n",
    "        for epoch in tqdm_notebook(range(1, num_epochs + 1)):\n",
    "            model.train()\n",
    "            G_losses, D_losses = [], []\n",
    "            \n",
    "            for _ in range(epoch_steps):\n",
    "                \n",
    "                D_step_loss = []\n",
    "                \n",
    "                # TRAINING D: Train D for D_steps (original WGAN paper e.g. 5)\n",
    "                for _ in range(D_steps):\n",
    "                    \n",
    "                    # Retrieve batch\n",
    "                    images = self.process_batch(self.train_iter)\n",
    "\n",
    "                    # Zero out gradients for D\n",
    "                    D_optimizer.zero_grad()\n",
    "                    \n",
    "                    # Train the discriminator using samples from the generator, compute sigmoid cross entropy loss to get D_loss = loss(D(x)) + loss(D(G(x)))\n",
    "                    D_loss = self.train_D(model, images)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    D_loss.backward()\n",
    "                    D_optimizer.step()\n",
    "                    \n",
    "                    # Log results, backpropagate the discriminator network\n",
    "                    D_step_loss.append(D_loss)\n",
    "                    \n",
    "                    # Clamp weights as per original paper (this is a crude way of ensuring K-Lipschitz...)\n",
    "                    self.clip_D_weights(model, clip)\n",
    "            \n",
    "                # We report D_loss in this way so that G_loss and D_loss have the same number of entries\n",
    "                D_losses.append(np.mean(D_step_loss))\n",
    "                                    \n",
    "                # TRAINING G: Zero out gradients for G\n",
    "                G_optimizer.zero_grad()\n",
    "\n",
    "                # Train the generator using predictions from D on the noise compared to true image labels\n",
    "                # (learn to generate examples from noise that fool the discriminator)\n",
    "                G_loss = self.train_G(model, images)\n",
    "\n",
    "                # Update parameters\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "\n",
    "                # Save relevant output for progress logging\n",
    "                G_losses.append(G_loss)\n",
    "                \n",
    "            # Progress logging\n",
    "            print (\"Epoch[%d/%d], G Loss: %.4f, D Loss: %.4f\"\n",
    "                   %(epoch, num_epochs, np.mean(G_losses), np.mean(D_losses))) \n",
    "            \n",
    "            # Visualize generator progress\n",
    "            fig = self.generate_images(model, epoch)\n",
    "            plt.show()\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def train_D(self, model, images):\n",
    "        \"\"\" Run 1 step of training for discriminator\n",
    "            \n",
    "            G_noise = randomly generated noise, x'\n",
    "            G_output = G(x'), generated images from noise\n",
    "            DX_score = D(x), probability x is fake where x are true images\n",
    "            DG_score = D(G(x')), probability G(x') is fake where x' is noise\n",
    "        \"\"\"      \n",
    "        \n",
    "        # Sample from the generator\n",
    "        G_noise = self.compute_noise(images.shape[0], model.z_dim)\n",
    "        G_output = model.G(G_noise)\n",
    "        \n",
    "        # Score real, generated images\n",
    "        DX_score = model.D(images) # D(x), \"real\"\n",
    "        DG_score = model.D(G_output) # D(G(x')), \"fake\"\n",
    "        \n",
    "        # Compute loss E[D(x)] - E[D(G(x'))]\n",
    "        D_loss = -(torch.mean(DX_score) - torch.mean(DG_score))\n",
    "        \n",
    "        return D_loss\n",
    "    \n",
    "    def train_G(self, model, images):\n",
    "        \"\"\" Run 1 step of training for generator\n",
    "        \n",
    "            G_noise = randomly generated noise, x'\n",
    "            G_output = G(x')\n",
    "            DG_score = D(G(x'))\n",
    "        \"\"\"\n",
    "        # Get noise, classify it using G, then classify the output of G using D.\n",
    "        noise = self.compute_noise(images.shape[0], model.z_dim) # x'\n",
    "        G_output = model.G(noise) # G(x')\n",
    "        DG_score = model.D(G_output) # D(G(x'))\n",
    "        \n",
    "        # Compute WGAN G loss\n",
    "        G_loss = -(torch.mean(DG_score))\n",
    "        \n",
    "        return G_loss\n",
    "    \n",
    "    def compute_noise(self, batch_size, z_dim):\n",
    "        \"\"\" Compute random noise for the generator to learn to make images from \"\"\"\n",
    "        return to_var(torch.randn(batch_size, z_dim))\n",
    "    \n",
    "    def generate_images(self, model, epoch, num_outputs = 25, save = True):\n",
    "        \"\"\" Visualize progress of generator learning \"\"\"\n",
    "        noise = self.compute_noise(num_outputs, model.z_dim)\n",
    "        images = model.G(noise)\n",
    "        images = images.view(images.shape[0], 28, 28)\n",
    "        size_figure_grid = int(num_outputs**0.5)\n",
    "        fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "        for i, j in product(range(size_figure_grid), range(size_figure_grid)):\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)\n",
    "            ax[i,j].cla()\n",
    "            ax[i,j].imshow(images[i+j].data.numpy(), cmap='gray') \n",
    "        \n",
    "        if save:\n",
    "            if not os.path.exists('../viz/w-gan/'):\n",
    "                os.makedirs('../viz/w-gan/')\n",
    "            torchvision.utils.save_image(images.unsqueeze(1).data.cpu(), '../viz/w-gan/reconst_%d.png' %(epoch), nrow = 5)\n",
    "        return fig\n",
    "    \n",
    "    def process_batch(self, iterator):\n",
    "        \"\"\" Generate a process batch to be input into the discriminator D \"\"\"\n",
    "        images, _ = next(iter(iterator))\n",
    "        images = to_var(images.view(images.shape[0], -1))\n",
    "        return images\n",
    "    \n",
    "    def clip_D_weights(self, model, clip):\n",
    "        for parameter in model.D.parameters():\n",
    "            parameter.data.clamp_(-clip, clip)    \n",
    "\n",
    "    def save_model(self, model, savepath):\n",
    "        \"\"\" Save model state dictionary \"\"\"\n",
    "        torch.save(model.state_dict(), savepath + 'saved_gan.pth')\n",
    "    \n",
    "    def load_model(self, loadpath,  model = None):\n",
    "        \"\"\" Load state dictionary into model. If model not specified, instantiate it \"\"\"\n",
    "        if not model:\n",
    "            model = WGAN()\n",
    "        state = torch.load(loadpath)\n",
    "        model.load_state_dict(state)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WGAN(image_size = 784, hidden_dim = 128, z_dim = 20)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "trainer = Trainer(train_iter, val_iter, test_iter)\n",
    "model = trainer.train(model = model, num_epochs = 50, G_lr = 5e-5, D_lr = 5e-5, D_steps = 5, clip = 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
