{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" (Autoencoder)\n",
    "Standard Autoencoder\n",
    "\n",
    "Autoencoders take an input representation, encode it into a reduced dimensionality\n",
    "space using an 'encoder network', and then decode it using a 'decoder network' back\n",
    "to its original representation\n",
    "\"\"\"\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "from load_data import get_data\n",
    "\n",
    "def to_cuda(x):\n",
    "    \"\"\" Cuda-erize a tensor \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "# Enable Jupyter notebook plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in binzarized MNIST data, separate into data loaders\n",
    "train_iter, val_iter, test_iter = get_data()\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" Feedforward network encoder. Input is an image, output is encoded \n",
    "    vector representation of that image.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.linear(x))\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\" Feedforward network decoder. Input is an encoded vector representation, \n",
    "    output is reconstructed image.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, image_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim, image_size)\n",
    "        \n",
    "    def forward(self, encoder_output):\n",
    "        return F.sigmoid(self.linear(encoder_output))\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\" Autoencoder super class to encode then decode an image\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size=784, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(image_size=image_size, hidden_dim=hidden_dim)\n",
    "        self.decoder = Decoder(hidden_dim=hidden_dim, image_size=image_size)\n",
    "                     \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "class AutoencoderTrainer:\n",
    "    def __init__(self, model, train_iter, val_iter, test_iter, viz=False):\n",
    "        \"\"\" Object to hold data iterators, train the model \"\"\"\n",
    "        self.model = to_cuda(model)\n",
    "        self.name = model.__class__.__name__\n",
    "        \n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "        \n",
    "        self.debugging_image, _ = next(iter(val_iter))\n",
    "        self.viz = viz\n",
    "    \n",
    "    def train(self, num_epochs, lr=1e-3, weight_decay=1e-5):\n",
    "        \"\"\" Train a Variational Autoencoder\n",
    "            Logs progress using total loss, reconstruction loss, kl_divergence, and validation loss\n",
    "\n",
    "        Inputs:\n",
    "            num_epochs: int, number of epochs to train for\n",
    "            lr: float, learning rate for Adam optimizer (default 1e-3)\n",
    "            weight_decay: float, weight decay for Adam optimizer (default 1e-5)\n",
    "        \"\"\"   \n",
    "        \n",
    "        # Initialize best validation loss for early stopping\n",
    "        best_val_loss = 1e10\n",
    "        \n",
    "        # Adam optimizer, sigmoid cross entropy for reconstructing binary MNIST\n",
    "        optimizer = torch.optim.Adam(params=[p for p in self.model.parameters() if p.requires_grad], \n",
    "                                     lr=lr, \n",
    "                                     weight_decay=weight_decay)\n",
    "        \n",
    "        # Begin training\n",
    "        for epoch in tqdm_notebook(range(1, num_epochs+1)):\n",
    "            \n",
    "            self.model.train()\n",
    "            epoch_loss = []\n",
    "            \n",
    "            for batch in self.train_iter:\n",
    "                \n",
    "                # Zero out gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Compute reconstruction loss, Kullback-Leibler divergence for a batch\n",
    "                batch_loss = self.compute_batch(batch)\n",
    "                \n",
    "                # Update parameters\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Log metrics\n",
    "                epoch_loss.append(batch_loss.item())\n",
    "            \n",
    "            # Test the model on the validation set\n",
    "            val_loss = self.evaluate(self.val_iter)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                self.best_model = deepcopy(self.model)\n",
    "                best_val_loss = val_loss\n",
    "                \n",
    "            # Progress logging\n",
    "            print (\"Epoch[%d/%d], Train Loss: %.4f, Val Loss: %.4f\" \n",
    "                   %(epoch, num_epochs, np.mean(epoch_loss), val_loss))\n",
    "            \n",
    "            # Debugging and visualization purposes\n",
    "            if self.viz:\n",
    "                self.reconstruct_images(self.debugging_image, epoch)\n",
    "                plt.show()\n",
    "                \n",
    "    def compute_batch(self, batch):\n",
    "        \"\"\" Compute loss for a batch of examples \"\"\"\n",
    "        images, _ = batch\n",
    "        images = to_cuda(images.view(images.shape[0], -1))\n",
    "        \n",
    "        output = self.model(images)\n",
    "        \n",
    "        recon_loss = F.binary_cross_entropy(output, images, size_average=False)\n",
    "        \n",
    "        return recon_loss\n",
    "    \n",
    "    def evaluate(self, iterator):\n",
    "        \"\"\" Evaluate on a given dataset \"\"\"\n",
    "        return np.mean([self.compute_batch(batch).item() for batch in iterator])\n",
    "    \n",
    "    def reconstruct_images(self, images, epoch, save=True):\n",
    "        \"\"\"Reconstruct a fixed input at each epoch for progress visualization \"\"\"\n",
    "        # Reshape images, VAE output\n",
    "        images = to_cuda(images.view(images.shape[0], -1))\n",
    "        reconst_images = self.model(images)\n",
    "        reconst_images = reconst_images.view(reconst_images.shape[0], 28, 28)\n",
    "        \n",
    "        # Plot\n",
    "        plt.close()\n",
    "        size_figure_grid = int(reconst_images.shape[0]**0.5)\n",
    "        fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "        for i, j in product(range(size_figure_grid), range(size_figure_grid)):\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)\n",
    "            ax[i,j].cla()\n",
    "            ax[i,j].imshow(reconst_images[i+j].data.numpy(), cmap='gray')\n",
    "        \n",
    "        # Save\n",
    "        if save:\n",
    "            outname = '../viz/' + self.name + '/'\n",
    "            if not os.path.exists(outname):\n",
    "                os.makedirs(outname)\n",
    "            torchvision.utils.save_image(images.data, \n",
    "                                         outname + 'real.png',\n",
    "                                         nrow=size_figure_grid)\n",
    "            torchvision.utils.save_image(reconst_images.unsqueeze(1).data, \n",
    "                                         outname + 'reconst_%d.png' %(epoch),\n",
    "                                         nrow=size_figure_grid)\n",
    "    \n",
    "    def save_model(self, savepath):\n",
    "        \"\"\" Save model state dictionary \"\"\"\n",
    "        torch.save(self.model.state_dict(), savepath)\n",
    "    \n",
    "    def load_model(self, loadpath):\n",
    "        \"\"\" Load state dictionary into model. If model not specified, instantiate it \"\"\"\n",
    "        state = torch.load(loadpath)\n",
    "        self.model.load_state_dict(state)\n",
    "\n",
    "\n",
    "model = Autoencoder(image_size=784, \n",
    "                    hidden_dim=32)\n",
    "\n",
    "trainer = AutoencoderTrainer(model=model,\n",
    "                             train_iter=train_iter, \n",
    "                             val_iter=val_iter, \n",
    "                             test_iter=test_iter,\n",
    "                             viz=True)\n",
    "\n",
    "trainer.train(num_epochs=5,\n",
    "              lr=1e-3,\n",
    "              weight_decay=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
