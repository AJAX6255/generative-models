{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9827f03a781402889210d751b494dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" (InfoGAN)\n",
    "\n",
    "From the paper:\n",
    "\"In this paper, we present a simple modification to the generative adversarial \n",
    "network objective that encourages it to learn interpretable and meaningful \n",
    "representations. We do so by maximizing the mutual information between a fixed \n",
    "small subset of the GAN’s noise variables and the observations, which turns out \n",
    "to be relatively straightforward. Despite its simplicity, we found our method to be\n",
    "surprisingly effective: it was able to discover highly semantic and meaningful \n",
    "hidden representations on a number of image datasets: digits (MNIST), faces (CelebA), \n",
    "and house numbers (SVHN). \"\"\n",
    "\n",
    "The Generator input is split into two parts: a traditional \"noise\" vector (z)\n",
    "and a latent \"code” vector (c) that targets the salient structured semantic features of \n",
    "the data distribution. These vectors are made meaningful by maximizing the mutual \n",
    "information lower bound between c and the G(c, z). Since mutual information is\n",
    "inefficient to compute directly, we estimate it using an auxiliary network Q.\n",
    "\n",
    "The auxiliary network Q(c|x) approximates P(c|x), the true posterior. We use this to \n",
    "compute the mutual information by sampling c from our assumed prior P(c), sampling a \n",
    "noise vector z, using them both to sample  x ~ G(c, z), and then passing x to Q(c|x). \n",
    "We then use Q(c|x) to maximize the mutual information between c and G(z, c) and \n",
    "backpropagate its estimate back to both G and Q.\n",
    "\n",
    "https://arxiv.org/pdf/1606.03657.pdf\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "from load_data import get_data\n",
    "\n",
    "def to_cuda(x):\n",
    "    \"\"\" Cuda-erize a tensor \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "# Enable Jupyter notebook plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in binarized MNIST data, separate into data loaders\n",
    "# train_iter, val_iter, test_iter = get_data()\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator. Input is noise and latent variables, output is a generated image. \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim, disc_dim, cont_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(z_dim + disc_dim + cont_dim, hidden_dim)\n",
    "        self.generate = nn.Linear(hidden_dim, image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        generation = torch.sigmoid(self.generate(activated))\n",
    "        return generation\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Discriminator. Input is an image (real or generated), output is P(generated), \n",
    "    continuous latent variables, discrete latent variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(locals())\n",
    "\n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        self.discriminator = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        discrimination = torch.sigmoid(self.discriminator(activated))\n",
    "        return discrimination\n",
    "\n",
    "    \n",
    "class Q(nn.Module):\n",
    "    \"\"\" Auxiliary network Q(c|x) that approximates P(c|x), the true posterior.\n",
    "    Input is an image, output are latent variables.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, disc_dim, cont_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.__dict__.update(locals())\n",
    "\n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        self.inference = nn.Linear(hidden_dim, disc_dim+cont_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        inferred = self.inference(activated)\n",
    "        discrete, continuous = inferred[:, :self.disc_dim], inferred[:, self.disc_dim:]\n",
    "        return discrete, continuous\n",
    "\n",
    "\n",
    "class InfoGAN(nn.Module):\n",
    "    \"\"\" Super class to contain both Discriminator (D) and Generator (G) \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim, disc_dim, cont_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__dict__.update(locals())\n",
    "        \n",
    "        self.G = Generator(image_size, hidden_dim, z_dim, disc_dim, cont_dim)\n",
    "        self.D = Discriminator(image_size, hidden_dim, output_dim)\n",
    "        self.Q = Q(image_size, hidden_dim, disc_dim, cont_dim)\n",
    "\n",
    "    \n",
    "class InfoGANTrainer:\n",
    "    \"\"\" Object to hold data iterators, train a GAN variant \n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_iter, val_iter, test_iter, viz=False):\n",
    "        self.model = to_cuda(model)\n",
    "        self.name = model.__class__.__name__\n",
    "        \n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "        \n",
    "        self.Glosses = []\n",
    "        self.Dlosses = []\n",
    "        self.MIlosses = []\n",
    "        \n",
    "        self.viz = viz\n",
    "            \n",
    "    def train(self, num_epochs, G_lr=2e-4, D_lr=2e-4, D_steps=1):\n",
    "        \"\"\" Train a vanilla GAN using the non-saturating gradients loss for the generator. \n",
    "            Logs progress using G loss, D loss, G(x), D(G(x)), visualizations of Generator output.\n",
    "\n",
    "        Inputs:\n",
    "            num_epochs: int, number of epochs to train for\n",
    "            G_lr: float, learning rate for generator's Adam optimizer (default 2e-4)\n",
    "            D_lr: float, learning rate for discriminator's Adam optimizer (default 2e-4)\n",
    "            D_steps: int, training step ratio for how often to train D compared to G (default 1)\n",
    "        \"\"\"\n",
    "        # Initialize optimizers\n",
    "        parameters = {'D': [p for p in self.model.D.parameters() if p.requires_grad],\n",
    "                      'G': [p for p in self.model.G.parameters() if p.requires_grad],\n",
    "                      'Q': [p for p in self.model.Q.parameters() if p.requires_grad]}\n",
    "        \n",
    "        G_optimizer = optim.Adam(params=parameters['G'], lr=G_lr)\n",
    "        D_optimizer = optim.Adam(params=parameters['D'], lr=D_lr)\n",
    "        MI_optimizer = optim.Adam(params=(parameters['G']+parameters['Q']), lr=G_lr)\n",
    "    \n",
    "        # Approximate steps/epoch given D_steps per epoch \n",
    "        # --> roughly train in the same way as if D_step (1) == G_step (1)\n",
    "        epoch_steps = int(np.ceil(len(train_iter) / (D_steps))) \n",
    "        \n",
    "        # Begin training\n",
    "        for epoch in tqdm_notebook(range(1, num_epochs+1)):\n",
    "            self.model.train()\n",
    "            G_losses, D_losses, MI_losses = [], [], []\n",
    "            \n",
    "            for _ in range(epoch_steps):\n",
    "                \n",
    "                D_step_loss = []\n",
    "                \n",
    "                for _ in range(D_steps): \n",
    "\n",
    "                    # Reshape images\n",
    "                    images = self.process_batch(self.train_iter)\n",
    "\n",
    "                    # TRAINING D: Zero out gradients for D\n",
    "                    D_optimizer.zero_grad()\n",
    "\n",
    "                    # Learn to discriminate between real and generated images\n",
    "                    D_loss = self.train_D(images)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    D_loss.backward()\n",
    "                    D_optimizer.step()\n",
    "                    \n",
    "                    # Log results, backpropagate the discriminator network\n",
    "                    D_step_loss.append(D_loss.item())\n",
    "                                                        \n",
    "                # So that G_loss and D_loss have the same number of entries.\n",
    "                D_losses.append(np.mean(D_step_loss))\n",
    "                \n",
    "                # TRAINING G: Zero out gradients for G\n",
    "                G_optimizer.zero_grad()\n",
    "\n",
    "                # Learn to generate images that fool the discriminator\n",
    "                G_loss = self.train_G(images)\n",
    "                \n",
    "                # Log results, update parameters\n",
    "                G_losses.append(G_loss.item())\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "                \n",
    "                # TRAINING Q: Zero out gradients for Q\n",
    "                MI_optimizer.zero_grad()\n",
    "                \n",
    "                # Learn to estimate Mutual Information\n",
    "                MI_loss = self.train_Q(images)\n",
    "\n",
    "                # Update parameters\n",
    "                MI_losses.append(MI_loss.item())\n",
    "                MI_loss.backward()\n",
    "                MI_optimizer.step()\n",
    "            \n",
    "            # Save progress\n",
    "            self.Glosses.extend(G_losses)\n",
    "            self.Dlosses.extend(D_losses)\n",
    "            self.MIlosses.extend(MI_losses)\n",
    "                            \n",
    "            # Progress logging\n",
    "            print (\"Epoch[%d/%d], G Loss: %.4f, D Loss: %.4f, MI Loss: %.4f\"\n",
    "                   %(epoch, num_epochs, np.mean(G_losses), \n",
    "                     np.mean(D_losses), np.mean(MI_losses))) \n",
    "            self.num_epochs = epoch\n",
    "            \n",
    "            # Visualize generator progress\n",
    "            self.generate_images(epoch)\n",
    "            \n",
    "            if self.viz:\n",
    "                plt.show()\n",
    "                \n",
    "    def train_D(self, images):\n",
    "        \"\"\" Run 1 step of training for discriminator\n",
    "\n",
    "        Input:\n",
    "            images: batch of images (reshaped to [batch_size, 784])\n",
    "        Output:\n",
    "            D_loss: non-saturing loss for discriminator, \n",
    "\n",
    "        \"\"\"    \n",
    "        # Generate labels (ones indicate real images, zeros indicate generated)\n",
    "        X_labels = to_cuda(torch.ones(images.shape[0], 1)) \n",
    "        G_labels = to_cuda(torch.zeros(images.shape[0], 1)) \n",
    "        \n",
    "        # Classify the real batch images, get the loss for these \n",
    "        DX_score = self.model.D(images)\n",
    "        DX_loss = F.binary_cross_entropy(DX_score, X_labels)\n",
    "        \n",
    "        # Sample noise z, generate output G(c, z)\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim, \n",
    "                                   self.model.disc_dim, self.model.cont_dim)\n",
    "        G_output = self.model.G(noise)\n",
    "        \n",
    "        # Classify the fake batch images, get the loss for these using sigmoid cross entropy\n",
    "        DG_score = self.model.D(G_output)\n",
    "        DG_loss = F.binary_cross_entropy(DG_score, G_labels)\n",
    "        \n",
    "        # Compute vanilla (original paper) D loss\n",
    "        D_loss = DX_loss + DG_loss\n",
    "        \n",
    "        return D_loss\n",
    "    \n",
    "    def train_G(self, images):\n",
    "        \"\"\" Run 1 step of training for generator\n",
    "        \n",
    "        Input:\n",
    "            images: batch of images reshaped to [batch_size, -1]    \n",
    "        Output:\n",
    "            G_loss: non-saturating loss for how well G(z) fools D\n",
    "        \n",
    "        \"\"\"        \n",
    "        # Generate labels for the generator batch images (all 0, since they are fake)\n",
    "        G_labels = to_cuda(torch.ones(images.shape[0], 1)) \n",
    "        \n",
    "        # Get noise (denoted z), classify it using G, then classify the output of G using D.\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim, \n",
    "                                   self.model.disc_dim, self.model.cont_dim) # c=[c1, c2], z\n",
    "        G_output = self.model.G(noise) # G(c, z)\n",
    "        DG_score = self.model.D(G_output) # D(G(c, z))\n",
    "        \n",
    "        # Compute the non-saturating loss for how D did versus the generations of G using sigmoid cross entropy\n",
    "        G_loss = F.binary_cross_entropy(DG_score, G_labels)\n",
    "        \n",
    "        return G_loss\n",
    "    \n",
    "    def train_Q(self, images):\n",
    "        \"\"\" Run 1 step of training for auxiliary approximator network\n",
    "        \n",
    "        Input:\n",
    "            images: batch of images reshaped to [batch_size, -1]    \n",
    "        Output:\n",
    "            MI_loss: Approximation of mutual information \n",
    "        \"\"\"\n",
    "        # Generate labels for the generator batch images (all 0, since they are fake)\n",
    "        G_labels = to_cuda(torch.zeros(images.shape[0], 1)) \n",
    "        \n",
    "        # Sample noise z, generate output G(c, z)\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim, \n",
    "                                   self.model.disc_dim, self.model.cont_dim)\n",
    "        \n",
    "        # Transform noise using G\n",
    "        G_output = self.model.G(noise)\n",
    "        \n",
    "        # Approximate true posterior for categorical, Gaussian latent variables\n",
    "        Q_discrete, Q_continuous = self.model.Q(G_output)\n",
    "        \n",
    "        # Compute mutual information loss\n",
    "        # Discrete component\n",
    "        discrete_target = noise[:, self.model.z_dim:self.model.z_dim+self.model.disc_dim]\n",
    "        disc_loss = F.cross_entropy(Q_discrete, \n",
    "                                    torch.max(discrete_target, 1)[1])\n",
    "        \n",
    "        # Continuous component\n",
    "        continuous_target = noise[:, self.model.z_dim+self.model.disc_dim:]\n",
    "        cont_loss = F.mse_loss(Q_continuous, continuous_target)\n",
    "        \n",
    "        # Sum it up\n",
    "        MI_loss = disc_loss + cont_loss\n",
    "        \n",
    "        return MI_loss\n",
    "        \n",
    "        \n",
    "    def compute_noise(self, batch_size, z_dim, disc_dim, cont_dim):\n",
    "        \"\"\" Compute random noise for the generator to learn to make images \"\"\"\n",
    "        # Noise vector (z)\n",
    "        z = torch.randn(batch_size, z_dim)\n",
    "        \n",
    "        # Uniformly distributed categorical latent variables (c1)\n",
    "        disc_c = torch.zeros((batch_size, disc_dim))\n",
    "        categorical = torch.randint(0, disc_dim, (batch_size,), dtype=torch.long)\n",
    "        disc_c[range(batch_size), categorical] = 1\n",
    "        \n",
    "        # Gaussian continuous latent variables (c2)\n",
    "        cont_c = torch.randn(batch_size, cont_dim)\n",
    "        \n",
    "        return to_cuda(torch.cat((z, disc_c, cont_c), dim=1))\n",
    "    \n",
    "    def process_batch(self, iterator):\n",
    "        \"\"\" Generate a process batch to be input into the discriminator D \"\"\"\n",
    "        images, _ = next(iter(iterator))\n",
    "        images = to_cuda(images.view(images.shape[0], -1))\n",
    "        return images\n",
    "    \n",
    "    def generate_images(self, epoch, num_outputs=36, save=True):\n",
    "        \"\"\" Visualize progress of generator learning \"\"\"\n",
    "        # Turn off any regularization\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Sample noise vector\n",
    "        noise = self.compute_noise(num_outputs, self.model.z_dim, \n",
    "                                   self.model.disc_dim, self.model.cont_dim) \n",
    "        \n",
    "        # Transform noise to image\n",
    "        images = self.model.G(noise)\n",
    "        \n",
    "        # Reshape to proper image size\n",
    "        images = images.view(images.shape[0], 28, 28)\n",
    "        \n",
    "        # Plot\n",
    "        plt.close()\n",
    "        size_figure_grid = int(num_outputs**0.5)\n",
    "        fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "        for i, j in product(range(size_figure_grid), range(size_figure_grid)):\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)\n",
    "            ax[i,j].cla()\n",
    "            ax[i,j].imshow(images[i+j].data.numpy(), cmap='gray') \n",
    "        \n",
    "        # Save images if desired\n",
    "        if save:\n",
    "            outname = '../viz/' + self.name + '/'\n",
    "            if not os.path.exists(outname):\n",
    "                os.makedirs(outname)\n",
    "            torchvision.utils.save_image(images.unsqueeze(1).data, \n",
    "                                         outname + 'reconst_%d.png'\n",
    "                                         %(epoch), nrow = 5)\n",
    "    \n",
    "    def viz_loss(self):\n",
    "        \"\"\" Visualize loss for the generator, discriminator \"\"\"\n",
    "        # Set style, figure size\n",
    "        plt.style.use('ggplot')\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "\n",
    "        # Plot Discriminator loss in red, Generator loss in green\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Dlosses, 'r')\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Glosses, 'g')\n",
    "        \n",
    "        # Add legend, title\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, savepath):\n",
    "        \"\"\" Save model state dictionary \"\"\"\n",
    "        torch.save(self.model.state_dict(), savepath)\n",
    "    \n",
    "    def load_model(self, loadpath):\n",
    "        \"\"\" Load state dictionary into model \"\"\"\n",
    "        state = torch.load(loadpath)\n",
    "        self.model.load_state_dict(state)\n",
    "\n",
    "\n",
    "model = InfoGAN(image_size=784, \n",
    "                hidden_dim=256, \n",
    "                z_dim=62,\n",
    "                disc_dim=2,\n",
    "                cont_dim=10)\n",
    "\n",
    "trainer = InfoGANTrainer(model=model, \n",
    "                         train_iter=train_iter, \n",
    "                         val_iter=val_iter, \n",
    "                         test_iter=test_iter,\n",
    "                         viz=True)\n",
    "\n",
    "trainer.train(num_epochs=25, \n",
    "              G_lr=2e-4,\n",
    "              D_lr=2e-4, \n",
    "              D_steps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
