{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" (WGANGP)\n",
    "Wasserstein GAN with Gradient Penalties ('improved methods for WGAN training')\n",
    "\n",
    "https://arxiv.org/pdf/1704.00028.pdf\n",
    "\n",
    "The output of WGANGP's D is unbounded unless passed through an activation function. In this implementation,\n",
    "we include a sigmoid activation function as this empirically improves visualizations for binary MNIST.\n",
    "\n",
    "WGAN GP roposes a gradient penalty to add to the WGAN discriminator loss as an alternative method for enforcing \n",
    "the Lipschitz constraint (previously done via weight clipping). This penalty does not suffer from the biasing\n",
    "of the discriminator toward simple funtions due to weight clipping. Additionally, the reformulation of the \n",
    "discriminator by adding a gradient penaltyterm makes batch normalization not necessary. This is notable because \n",
    "batch normalization implicitly changes the discriminator's problem from mapping one-to-one to many-to-many.\n",
    "\"\"\"\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "from load_data import get_data\n",
    "\n",
    "def to_cuda(x):\n",
    "    \"\"\" Cuda-erize a tensor \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "# Enable Jupyter notebook plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in binarized MNIST data, separate into data loaders\n",
    "# train_iter, val_iter, test_iter = get_data()\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator. Input is noise, output is a generated image. \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.generate = nn.Linear(hidden_dim, image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        generation = F.sigmoid(self.generate(activated))\n",
    "        return generation\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Critic (not trained to classify). Input is an image (real or generated), \n",
    "    output is the approximate least-squares distance between z~P(G(z)) and real.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        self.discriminate = nn.Linear(hidden_dim, output_dim)     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        discrimination = self.discriminate(activated)\n",
    "        return discrimination\n",
    "\n",
    "\n",
    "class WGANGP(nn.Module):\n",
    "    \"\"\" Super class to contain both Discriminator (D) and Generator (G) \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.G = Generator(image_size, hidden_dim, z_dim)\n",
    "        self.D = Discriminator(image_size, hidden_dim, output_dim)\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "\n",
    "\n",
    "class WGANGPTrainer:\n",
    "    \"\"\" Object to hold data iterators, train a GAN variant \n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_iter, val_iter, test_iter, viz=False):\n",
    "        self.model = to_cuda(model)\n",
    "        self.name = model.__class__.__name__\n",
    "        \n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "        \n",
    "        self.Glosses = []\n",
    "        self.Dlosses = []\n",
    "        \n",
    "        self.viz = viz\n",
    "\n",
    "    def train(self, num_epochs, G_lr=1e-4, D_lr=1e-4, D_steps=5):\n",
    "        \"\"\" Train a WGAN GP\n",
    "            Logs progress using G loss, D loss, G(x), D(G(x)), visualizations of Generator output.\n",
    "\n",
    "        Inputs:\n",
    "            num_epochs: int, number of epochs to train for\n",
    "            G_lr: float, learning rate for generator's Adam optimizer (default 1e-4)\n",
    "            D_lr: float, learning rate for discriminator's Adam optimizer (default 1e-4)\n",
    "            D_steps: int, training step ratio for how often to train D compared to G (default 5)\n",
    "        \"\"\"\n",
    "        # Initialize optimizers\n",
    "        G_optimizer = torch.optim.Adam(params=[p for p in self.model.G.parameters() if p.requires_grad], lr=G_lr)\n",
    "        D_optimizer = torch.optim.Adam(params=[p for p in self.model.D.parameters() if p.requires_grad], lr=D_lr)\n",
    "    \n",
    "        # Approximate steps/epoch given D_steps per epoch --> roughly train in the same way as if D_step (1) == G_step (1)\n",
    "        epoch_steps = int(np.ceil(len(train_iter) / (D_steps))) \n",
    "        \n",
    "        # Begin training\n",
    "        for epoch in tqdm_notebook(range(1, num_epochs+1)):\n",
    "            self.model.train()\n",
    "            G_losses, D_losses = [], []\n",
    "            \n",
    "            for _ in range(epoch_steps):\n",
    "                \n",
    "                D_step_loss = []\n",
    "                \n",
    "                for _ in range(D_steps): \n",
    "\n",
    "                    # Reshape images\n",
    "                    images = self.process_batch(self.train_iter)\n",
    "\n",
    "                    # TRAINING D: Zero out gradients for D\n",
    "                    D_optimizer.zero_grad()\n",
    "\n",
    "                    # Train the discriminator to approximate the Wasserstein distance between real, generated\n",
    "                    # distributions                    \n",
    "                    D_loss = self.train_D(images)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    D_loss.backward()\n",
    "                    D_optimizer.step()\n",
    "                    \n",
    "                    # Log results, backpropagate the discriminator network\n",
    "                    D_step_loss.append(D_loss.item())\n",
    "                                                        \n",
    "                # We report D_loss in this way so that G_loss and D_loss have the same number of entries.\n",
    "                D_losses.append(np.mean(D_step_loss))\n",
    "                \n",
    "                # TRAINING G: Zero out gradients for G\n",
    "                G_optimizer.zero_grad()\n",
    "\n",
    "                # Train the generator to (roughly) minimize the approximated Wasserstein distance\n",
    "                G_loss = self.train_G(images)\n",
    "                \n",
    "                # Log results, update parameters\n",
    "                G_losses.append(G_loss.item())\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "            \n",
    "            # Save progress\n",
    "            self.Glosses.extend(G_losses)\n",
    "            self.Dlosses.extend(D_losses)\n",
    "                            \n",
    "            # Progress logging\n",
    "            print (\"Epoch[%d/%d], G Loss: %.4f, D Loss: %.4f\"\n",
    "                   %(epoch, num_epochs, np.mean(G_losses), np.mean(D_losses)))\n",
    "            self.num_epochs = epoch\n",
    "            \n",
    "            # Visualize generator progress\n",
    "            self.generate_images(epoch)\n",
    "            \n",
    "            if self.viz:\n",
    "                plt.show()       \n",
    "                        \n",
    "    def train_D(self, images, LAMBDA=10):\n",
    "        \"\"\" Run 1 step of training for discriminator\n",
    "\n",
    "        Input:\n",
    "            images: batch of images (reshaped to [batch_size, 784])\n",
    "        Output:\n",
    "            D_loss: Wasserstein loss for discriminator, \n",
    "            -E[D(x)] + E[D(G(z))] + λE[(||∇ D(εx + (1 − εG(z)))|| - 1)^2]\n",
    "        \"\"\"   \n",
    "        # ORIGINAL CRITIC STEPS:\n",
    "        # Sample noise, an output from the generator\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim)\n",
    "        G_output = self.model.G(noise)\n",
    "        \n",
    "        # Use the discriminator to sample real, generated images\n",
    "        DX_score = self.model.D(images) # D(z)\n",
    "        DG_score = self.model.D(G_output) # D(G(z))\n",
    "        \n",
    "        # GRADIENT PENALTY:\n",
    "        # Uniformly sample along one straight line per each batch entry. \n",
    "        epsilon = to_cuda(torch.rand(images.shape[0], 1).expand(images.size()))\n",
    "\n",
    "        # Generate images from the noise, ensure unit gradient norm 1\n",
    "        # See Section 4 and Algorithm 1 of original paper for full explanation.\n",
    "        G_interpolation = epsilon*images + (1-epsilon)*G_output # negation doesn't matter; we square later on\n",
    "        D_interpolation = self.model.D(G_interpolation)\n",
    "\n",
    "        # Compute the gradients of D with respect to the noise generated input\n",
    "        weight = to_cuda(torch.ones(D_interpolation.size()))\n",
    "            \n",
    "        gradients = torch.autograd.grad(outputs=D_interpolation, \n",
    "                                        inputs=G_interpolation,\n",
    "                                        grad_outputs=weight,\n",
    "                                        only_inputs=True,\n",
    "                                        create_graph=True,\n",
    "                                        retain_graph=True)[0]\n",
    "\n",
    "        # Full gradient penalty\n",
    "        grad_penalty = LAMBDA * torch.mean((gradients.norm(2, dim = 1) - 1) **2)\n",
    "        \n",
    "        # Compute WGAN-GP loss for D\n",
    "        D_loss = torch.mean(DG_score) - torch.mean(DX_score) + grad_penalty\n",
    "        \n",
    "        return D_loss\n",
    "    \n",
    "    def train_G(self, images):\n",
    "        \"\"\" Run 1 step of training for generator\n",
    "        \n",
    "        Input:\n",
    "            images: batch of images reshaped to [batch_size, -1]    \n",
    "        Output:\n",
    "            G_loss: wasserstein loss for generator, \n",
    "            -E[D(G(z))]\n",
    "        \"\"\"   \n",
    "        # Get noise, classify it using G, then classify the output of G using D.\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim) # z\n",
    "        G_output = self.model.G(noise) # G(z)\n",
    "        DG_score = self.model.D(G_output) # D(G(z))\n",
    "        \n",
    "        # Compute WGAN-GP loss for G (same loss as WGAN)\n",
    "        G_loss = -1 * (torch.mean(DG_score))\n",
    "        \n",
    "        return G_loss\n",
    "    \n",
    "    def compute_noise(self, batch_size, z_dim):\n",
    "        \"\"\" Compute random noise for the generator to learn to make images from \"\"\"\n",
    "        return to_cuda(torch.randn(batch_size, z_dim))\n",
    "    \n",
    "    def process_batch(self, iterator):\n",
    "        \"\"\" Generate a process batch to be input into the discriminator D \"\"\"\n",
    "        images, _ = next(iter(iterator))\n",
    "        images = to_cuda(images.view(images.shape[0], -1))\n",
    "        return images\n",
    "    \n",
    "    def generate_images(self, epoch, num_outputs=36, save=True):\n",
    "        \"\"\" Visualize progress of generator learning \"\"\"\n",
    "        # Turn off any regularization\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Sample noise vector\n",
    "        noise = self.compute_noise(num_outputs, self.model.z_dim)\n",
    "        \n",
    "        # Transform noise to image\n",
    "        images = self.model.G(noise)\n",
    "        \n",
    "        # Reshape to proper image size\n",
    "        images = images.view(images.shape[0], 28, 28)\n",
    "        \n",
    "        # Plot\n",
    "        plt.close()\n",
    "        size_figure_grid = int(num_outputs**0.5)\n",
    "        fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "        for i, j in product(range(size_figure_grid), range(size_figure_grid)):\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)\n",
    "            ax[i,j].cla()\n",
    "            ax[i,j].imshow(images[i+j].data.numpy(), cmap='gray') \n",
    "        \n",
    "        # Save images if desired\n",
    "        if save:\n",
    "            outname = '../viz/' + self.name + '/'\n",
    "            if not os.path.exists(outname):\n",
    "                os.makedirs(outname)\n",
    "            torchvision.utils.save_image(images.unsqueeze(1).data.cpu(), \n",
    "                                         outname + 'reconst_%d.png'\n",
    "                                         %(epoch), nrow = 5)\n",
    "    \n",
    "    def viz_loss(self):\n",
    "        \"\"\" Visualize loss for the generator, discriminator \"\"\"\n",
    "        # Set style, figure size\n",
    "        plt.style.use('ggplot')\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "\n",
    "        # Plot Discriminator loss in red, Generator loss in green\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Dlosses, 'r')\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Glosses, 'g')\n",
    "        \n",
    "        # Add legend, title\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, savepath):\n",
    "        \"\"\" Save model state dictionary \"\"\"\n",
    "        torch.save(self.model.state_dict(), savepath)\n",
    "    \n",
    "    def load_model(self, loadpath):\n",
    "        \"\"\" Load state dictionary into model \"\"\"\n",
    "        state = torch.load(loadpath)\n",
    "        self.model.load_state_dict(state)\n",
    "\n",
    "\n",
    "model = WGANGP(image_size=784, \n",
    "              hidden_dim=256, \n",
    "              z_dim=128)\n",
    "\n",
    "trainer = WGANGPTrainer(model=model, \n",
    "                        train_iter=train_iter, \n",
    "                        val_iter=val_iter, \n",
    "                        test_iter=test_iter,\n",
    "                        viz=True)\n",
    "\n",
    "trainer.train(num_epochs=25,\n",
    "              G_lr=1e-4,\n",
    "              D_lr=1e-4,\n",
    "              D_steps=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
