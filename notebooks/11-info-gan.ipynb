{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" (InfoGAN)\n",
    "\n",
    "From the paper:\n",
    "\"In this paper, we present a simple modification to the generative adversarial \n",
    "network objective that encourages it to learn interpretable and meaningful \n",
    "representations. We do so by maximizing the mutual information between a fixed \n",
    "small subset of the GAN’s noise variables and the observations, which turns out \n",
    "to be relatively straightforward. Despite its simplicity, we found our method to be\n",
    "surprisingly effective: it was able to discover highly semantic and meaningful \n",
    "hidden representations on a number of image datasets: digits (MNIST), faces (CelebA), \n",
    "and house numbers (SVHN). \"\"\n",
    "\n",
    "The Generator input is split into two parts: a traditional \"noise\" vector (z)\n",
    "and a latent \"code” vector (c) that targets the salient structured semantic features of \n",
    "the data distribution. These vectors are made meaningful by maximizing the mutual \n",
    "information lower bound between c and the G(z, c).\n",
    "\n",
    "https://arxiv.org/pdf/1606.03657.pdf\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "from load_data import get_data\n",
    "\n",
    "def to_cuda(x):\n",
    "    \"\"\" Cuda-erize a tensor \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return x\n",
    "\n",
    "# Enable Jupyter notebook plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in binarized MNIST data, separate into data loaders\n",
    "train_iter, val_iter, test_iter = get_data()\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator. Input is noise, output is a generated image. \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.generate = nn.Linear(hidden_dim, image_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        generation = torch.sigmoid(self.generate(activated))\n",
    "        return generation\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Discriminator. Input is an image (real or generated), output is P(generated).\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(image_size, hidden_dim)\n",
    "        self.discriminate = nn.Linear(hidden_dim, output_dim)     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        activated = F.relu(self.linear(x))\n",
    "        discrimination = torch.sigmoid(self.discriminate(activated))\n",
    "        return discrimination\n",
    "\n",
    "\n",
    "class InfoGAN(nn.Module):\n",
    "    \"\"\" Super class to contain both Discriminator (D) and Generator (G) \n",
    "    \"\"\"\n",
    "    def __init__(self, image_size, hidden_dim, z_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.G = Generator(image_size, hidden_dim, z_dim)\n",
    "        self.D = Discriminator(image_size, hidden_dim, output_dim)\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    \n",
    "class InfoGANTrainer:\n",
    "    \"\"\" Object to hold data iterators, train a GAN variant \n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_iter, val_iter, test_iter, viz=False):\n",
    "        self.model = to_cuda(model)\n",
    "        self.name = model.__class__.__name__\n",
    "        \n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "        \n",
    "        self.Glosses = []\n",
    "        self.Dlosses = []\n",
    "        \n",
    "        self.viz = viz\n",
    "            \n",
    "    def train(self, num_epochs, G_lr=2e-4, D_lr=2e-4, D_steps=1):\n",
    "        \"\"\" Train a vanilla GAN using the non-saturating gradients loss for the generator. \n",
    "            Logs progress using G loss, D loss, G(x), D(G(x)), visualizations of Generator output.\n",
    "\n",
    "        Inputs:\n",
    "            num_epochs: int, number of epochs to train for\n",
    "            G_lr: float, learning rate for generator's Adam optimizer (default 2e-4)\n",
    "            D_lr: float, learning rate for discriminator's Adam optimizer (default 2e-4)\n",
    "            D_steps: int, training step ratio for how often to train D compared to G (default 1)\n",
    "        \"\"\"\n",
    "        # Initialize optimizers\n",
    "        G_optimizer = torch.optim.Adam(params=[p for p in self.model.G.parameters() if p.requires_grad], lr=G_lr)\n",
    "        D_optimizer = torch.optim.Adam(params=[p for p in self.model.D.parameters() if p.requires_grad], lr=D_lr)\n",
    "    \n",
    "        # Approximate steps/epoch given D_steps per epoch --> roughly train in the same way as if D_step (1) == G_step (1)\n",
    "        epoch_steps = int(np.ceil(len(train_iter) / (D_steps))) \n",
    "        \n",
    "        # Begin training\n",
    "        for epoch in tqdm_notebook(range(1, num_epochs+1)):\n",
    "            self.model.train()\n",
    "            G_losses, D_losses = [], []\n",
    "            \n",
    "            for _ in range(epoch_steps):\n",
    "                \n",
    "                D_step_loss = []\n",
    "                \n",
    "                for _ in range(D_steps): \n",
    "\n",
    "                    # Reshape images\n",
    "                    images = self.process_batch(self.train_iter)\n",
    "\n",
    "                    # TRAINING D: Zero out gradients for D\n",
    "                    D_optimizer.zero_grad()\n",
    "\n",
    "                    # Train the discriminator to learn to discriminate between real and generated images\n",
    "                    D_loss = self.train_D(images)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    D_loss.backward()\n",
    "                    D_optimizer.step()\n",
    "                    \n",
    "                    # Log results, backpropagate the discriminator network\n",
    "                    D_step_loss.append(D_loss.item())\n",
    "                                                        \n",
    "                # We report D_loss in this way so that G_loss and D_loss have the same number of entries.\n",
    "                D_losses.append(np.mean(D_step_loss))\n",
    "                \n",
    "                # TRAINING G: Zero out gradients for G\n",
    "                G_optimizer.zero_grad()\n",
    "\n",
    "                # Train the generator to generate images that fool the discriminator\n",
    "                G_loss = self.train_G(images)\n",
    "                \n",
    "                # Log results, update parameters\n",
    "                G_losses.append(G_loss.item())\n",
    "                G_loss.backward()\n",
    "                G_optimizer.step()\n",
    "            \n",
    "            # Save progress\n",
    "            self.Glosses.extend(G_losses)\n",
    "            self.Dlosses.extend(D_losses)\n",
    "                            \n",
    "            # Progress logging\n",
    "            print (\"Epoch[%d/%d], G Loss: %.4f, D Loss: %.4f\"\n",
    "                   %(epoch, num_epochs, np.mean(G_losses), np.mean(D_losses))) \n",
    "            self.num_epochs = epoch\n",
    "            \n",
    "            # Visualize generator progress\n",
    "            self.generate_images(epoch)\n",
    "            \n",
    "            if self.viz:\n",
    "                plt.show()\n",
    "                \n",
    "    def train_D(self, images):\n",
    "        \"\"\" Run 1 step of training for discriminator\n",
    "\n",
    "        Input:\n",
    "            images: batch of images (reshaped to [batch_size, 784])\n",
    "        Output:\n",
    "            D_loss: non-saturing loss for discriminator, \n",
    "            -E[log(D(x))] - E[log(1 - D(G(z)))]\n",
    "        \"\"\"    \n",
    "        # Generate labels (ones indicate real images, zeros indicate generated)\n",
    "        X_labels = to_cuda(torch.ones(images.shape[0], 1)) \n",
    "        G_labels = to_cuda(torch.zeros(images.shape[0], 1)) \n",
    "        \n",
    "        # Classify the real batch images, get the loss for these \n",
    "        DX_score = self.model.D(images)\n",
    "        DX_loss = F.binary_cross_entropy(DX_score, X_labels)\n",
    "        \n",
    "        # Sample noise z, generate output G(z)\n",
    "        noise = self.compute_noise(images.shape[0], model.z_dim)\n",
    "        G_output = self.model.G(noise)\n",
    "        \n",
    "        # Classify the fake batch images, get the loss for these using sigmoid cross entropy\n",
    "        DG_score = self.model.D(G_output)\n",
    "        DG_loss = F.binary_cross_entropy(DG_score, G_labels)\n",
    "        \n",
    "        # Compute vanilla (original paper) D loss\n",
    "        D_loss = DX_loss + DG_loss\n",
    "        \n",
    "        return D_loss\n",
    "    \n",
    "    def train_G(self, images):\n",
    "        \"\"\" Run 1 step of training for generator\n",
    "        \n",
    "        Input:\n",
    "            images: batch of images reshaped to [batch_size, -1]    \n",
    "        Output:\n",
    "            G_loss: non-saturating loss for how well G(z) fools D, \n",
    "            -E[log(D(G(z)))]\n",
    "        \"\"\"        \n",
    "        # Generate labels for the generator batch images (all 0, since they are fake)\n",
    "        G_labels = to_cuda(torch.ones(images.shape[0], 1)) \n",
    "        \n",
    "        # Get noise (denoted z), classify it using G, then classify the output of G using D.\n",
    "        noise = self.compute_noise(images.shape[0], self.model.z_dim) # z\n",
    "        G_output = self.model.G(noise) # G(z)\n",
    "        DG_score = self.model.D(G_output) # D(G(z))\n",
    "        \n",
    "        # Compute the non-saturating loss for how D did versus the generations of G using sigmoid cross entropy\n",
    "        G_loss = F.binary_cross_entropy(DG_score, G_labels)\n",
    "        \n",
    "        return G_loss\n",
    "    \n",
    "    def compute_noise(self, batch_size, z_dim):\n",
    "        \"\"\" Compute random noise for the generator to learn to make images from \"\"\"\n",
    "        return to_cuda(torch.randn(batch_size, z_dim))\n",
    "    \n",
    "    def discrete_code(self, batch_size, z_dim):\n",
    "        \"\"\" Randomly distributed categorical latent variables \"\"\"\n",
    "        c = np.zeros((batch_size, z_dim))\n",
    "        categorical = np.random.randint(0, z_dim, batch_size)\n",
    "        c[range(batch_size), categorical] = 1\n",
    "        return to_cuda(torch.Tensor(code))\n",
    "    \n",
    "    def continuous_code(self, batch_size, z_dim):\n",
    "        return to_cuda(torch.Tensor(np.random.randn(batch_size, z_dim) * 0.5 + 0.0))\n",
    "    \n",
    "    def process_batch(self, iterator):\n",
    "        \"\"\" Generate a process batch to be input into the discriminator D \"\"\"\n",
    "        images, _ = next(iter(iterator))\n",
    "        images = to_cuda(images.view(images.shape[0], -1))\n",
    "        return images\n",
    "    \n",
    "    def generate_images(self, epoch, num_outputs=36, save=True):\n",
    "        \"\"\" Visualize progress of generator learning \"\"\"\n",
    "        # Turn off any regularization\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Sample noise vector\n",
    "        noise = self.compute_noise(num_outputs, self.model.z_dim)\n",
    "        \n",
    "        # Transform noise to image\n",
    "        images = self.model.G(noise)\n",
    "        \n",
    "        # Reshape to proper image size\n",
    "        images = images.view(images.shape[0], 28, 28)\n",
    "        \n",
    "        # Plot\n",
    "        plt.close()\n",
    "        size_figure_grid = int(num_outputs**0.5)\n",
    "        fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n",
    "        for i, j in product(range(size_figure_grid), range(size_figure_grid)):\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)\n",
    "            ax[i,j].cla()\n",
    "            ax[i,j].imshow(images[i+j].data.numpy(), cmap='gray') \n",
    "        \n",
    "        # Save images if desired\n",
    "        if save:\n",
    "            outname = '../viz/' + self.name + '/'\n",
    "            if not os.path.exists(outname):\n",
    "                os.makedirs(outname)\n",
    "            torchvision.utils.save_image(images.unsqueeze(1).data, \n",
    "                                         outname + 'reconst_%d.png'\n",
    "                                         %(epoch), nrow = 5)\n",
    "    \n",
    "    def viz_loss(self):\n",
    "        \"\"\" Visualize loss for the generator, discriminator \"\"\"\n",
    "        # Set style, figure size\n",
    "        plt.style.use('ggplot')\n",
    "        plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "\n",
    "        # Plot Discriminator loss in red, Generator loss in green\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Dlosses, 'r')\n",
    "        plt.plot(np.linspace(1, self.num_epochs, len(self.Dlosses)), self.Glosses, 'g')\n",
    "        \n",
    "        # Add legend, title\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, savepath):\n",
    "        \"\"\" Save model state dictionary \"\"\"\n",
    "        torch.save(self.model.state_dict(), savepath)\n",
    "    \n",
    "    def load_model(self, loadpath):\n",
    "        \"\"\" Load state dictionary into model \"\"\"\n",
    "        state = torch.load(loadpath)\n",
    "        self.model.load_state_dict(state)\n",
    "\n",
    "# model = InfoGAN(image_size=784, \n",
    "#               hidden_dim=256, \n",
    "#               z_dim=128)\n",
    "\n",
    "# trainer = InfoGANTrainer(model=model, \n",
    "#                        train_iter=train_iter, \n",
    "#                        val_iter=val_iter, \n",
    "#                        test_iter=test_iter,\n",
    "#                        viz=True)\n",
    "\n",
    "# trainer.train(num_epochs=25, \n",
    "#               G_lr=2e-4, \n",
    "#               D_lr=2e-4, \n",
    "#               D_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.random.multinomial(1, 10 * [float(1.0 / 10)],\n",
    "                                          size=[10])).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_x = torch.FloatTensor(self.batch_size, 1, 28, 28).cuda()\n",
    "label = torch.FloatTensor(self.batch_size).cuda()\n",
    "dis_c = torch.FloatTensor(self.batch_size, 10).cuda()\n",
    "con_c = torch.FloatTensor(self.batch_size, 2).cuda()\n",
    "noise = torch.FloatTensor(self.batch_size, 62).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8167,  0.3772,  0.1451,  0.5858,  0.0409,  0.2101,  0.4110, -0.1784,\n",
       "          0.2621,  1.2358],\n",
       "        [-0.0499, -0.3472, -1.1722,  0.2678, -0.2321, -0.3586, -0.0119, -0.2737,\n",
       "         -0.1089,  0.4942],\n",
       "        [-0.3976,  0.5503,  0.0553, -0.6882,  0.7961, -0.3377, -0.1622,  0.0986,\n",
       "         -0.2087, -0.4003],\n",
       "        [-0.4787,  0.5330,  0.1904, -1.0048, -0.1684,  0.5088, -0.0069, -0.3866,\n",
       "         -0.1516,  0.7155],\n",
       "        [ 0.0871, -1.1096, -0.1513, -0.1864,  0.4398, -0.2301,  0.4090, -0.4943,\n",
       "         -0.2718, -0.1424]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.random.randn(5, 10) * 0.5 + 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3850,  0.3367, -0.5648,  ..., -0.5966, -0.1753,  0.6119],\n",
       "        [-0.4176,  0.8222,  0.3787,  ..., -0.1547,  0.1506, -0.3886],\n",
       "        [-0.0974,  0.3372, -0.0439,  ...,  0.3419,  0.5537,  0.3183],\n",
       "        ...,\n",
       "        [ 0.4631, -0.5071,  0.2694,  ..., -0.2048, -0.5828,  0.2354],\n",
       "        [ 0.3200,  0.0720,  0.2960,  ...,  0.2946,  0.2431, -0.0116],\n",
       "        [-0.2538, -0.3455,  0.0388,  ...,  0.0065,  0.0180, -1.3905]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cuda(torch.Tensor(np.random.randn(100, 64) * 0.5 + 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_discrete_c(n_size, dim):\n",
    "    code = np.zeros((n_size, dim))\n",
    "    random_cate = np.random.randint(0, dim, n_size)\n",
    "    code[range(n_size), random_cate] = 1\n",
    "    return to_cuda(torch.Tensor(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4414, -0.3434, -0.0854, -0.1526, -0.8968],\n",
       "        [ 0.0283, -0.6033,  0.3400,  0.4386, -0.4224],\n",
       "        [ 0.4602,  0.0730, -0.0973, -0.5957, -0.2101],\n",
       "        [ 0.2695, -0.0637,  0.4636,  0.6081, -0.7417],\n",
       "        [ 0.2429, -0.4586,  0.0943, -0.1694,  0.1278],\n",
       "        [ 0.6369, -0.5725, -0.4205, -0.2046,  0.1934],\n",
       "        [-0.5997,  1.3792,  0.0808, -0.6309,  0.0621],\n",
       "        [-0.6252, -0.1120,  0.3336, -0.7573,  0.2322],\n",
       "        [-0.0265, -0.3666, -0.8169,  0.2990,  1.0263],\n",
       "        [ 0.5395, -0.5501, -0.6658, -0.2304, -1.1266]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.random.randn(n_size, dim) * 0.5 + 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_size, dim = 10, 5\n",
    "code = np.zeros((n_size, dim))\n",
    "random_cate = np.random.randint(0, dim, n_size)\n",
    "code[range(n_size), random_cate] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
